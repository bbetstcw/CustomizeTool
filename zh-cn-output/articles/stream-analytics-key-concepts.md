<properties 
	pageTitle="了解流分析关键概念 |Windows Azure" 
	description="了解 Azure 流分析的关键概念：流分析作业的组件，包括支持的输入和输出、作业配置和度量值。" 
	keywords="event processing,data stream,key concepts,serialization"	
	services="stream-analytics" 
	documentationCenter="" 
	authors="jeffstokes72" 
	manager="paulettm" 
	editor="cgronlun" />

<tags 
	ms.service="stream-analytics" 
	ms.date="08/19/2015" 
	wacn.date="09/15/2015" />


# 流分析关键概念：流分析作业基础指南 

Azure 流分析是一种完全托管的服务，可以在云中通过数据流进行低延迟、高度可用、可伸缩且复杂的事件处理。客户可以使用流分析来设置流式处理作业，以便分析数据流并进行近实时分析。本文介绍了流分析作业的关键概念。

## 在流分析中，你可以做些什么？
通过流分析，你可以：

- 针对大容量高速数据流进行复杂的事件处理。   
- 从全球分布的资产或设备（如联网汽车或公用电网）中收集事件数据。 
- 处理进行近实时监视和诊断所需的遥测数据。 
- 捕获和存档留待将来处理的实时事件

有关详细信息，请参阅 [Azure 流分析简介](/documentation/articles/stream-analytics-introduction)。

流分析作业包括所有下述项目：- 一个或多个输入源 - 对传入数据流的查询 - 输出目标。


## 输入

### 数据流

每个流分析作业定义必须包含至少一种可供作业使用和转换的数据流输入源。[Azure Blob 存储](http://azure.microsoft.com/documentation/services/storage/)和 [Azure 事件中心](http://azure.microsoft.com/services/event-hubs/)均可作为数据流输入源。事件中心输入源可用于从多个不同的设备和服务收集事件流，而 Blob 存储则可用作输入源来引入大量的数据。由于 blob 不对数据进行流式处理，因此基于 blob 的流分析作业在本质上不会是临时性的，除非 blob 中的记录包含时间戳。

### 引用数据
流分析还支持第二类输入源：引用数据。此类数据为辅助数据，用于执行关联性操作和查找操作，而且通常为静态数据或不会频繁更改的数据。只支持使用 [Azure Blob 存储](http://azure.microsoft.com/documentation/services/storage/)作为引用数据的输入源。引用数据源 blob 存在 50 MB 的大小限制。

若要支持刷新引用数据，用户需使用路径模式中的 {date} 和 {time} 令牌在输入配置中指定 blob 的列表。该作业将根据 blob 名称中使用 UTC 时区编码的日期和时间加载相应的 blob。

例如，如果作业在门户中使用下面这样的路径模式对引用输入进行了配置：/sample/{date}/{time}/products.csv，其中，日期格式为“YYYY-MM-DD”，时间格式为“HH:mm”，则该作业会在 2015 年 4 月 16 日下午 5:30（UTC 时区，相当于 PST 时区的 2015 年 4 月 16 日的上午 10:30）选取名为 /sample/2015-04-16/17:30/products.csv 的文件。


### 序列化
若要确保查询行为的正确性，流分析必须了解用于传入数据流的序列化格式。当前支持的序列化格式包括适用于数据流的 JSON、CSV、Avro，以及适用于引用数据的 CSV 或 JSON。

### 生成的属性
将会生成更多使用事件元数据的字段，具体取决于作业中使用的输入类型。可以对这些字段进行查询，就像对其他输入列一样。如果现有事件的字段名称与下列某个属性相同，则会使用输入元数据对其进行覆盖。

<table border="1">
	<tr>
		<th></th>
		<th>属性</th>
		<th>说明</th>
	</tr>
	<tr>
		<td rowspan="4" valign="top"><strong>Blob</strong></td>
		<td>BlobName</td>
		<td>提供事件的输入 blob 的名称。</td>
	</tr>
	<tr>
		<td>EventProcessedUtcTime</td>
		<td>处理 blob 记录的日期和时间。</td>
	</tr>
	<tr>
		<td>BlobLastModifiedUtcTime</td>
		<td>上次修改 blob 的日期和时间。</td>
	</tr>
	<tr>
		<td>PartitionId</td>
		<td>输入适配器的从零开始的分区 ID。</td>
	</tr>
	<tr>
		<td rowspan="3" valign="top"><b>事件中心</b></td>
		<td>EventProcessedUtcTime</td>
		<td>处理事件的日期和时间。</td>
	</tr>
	<tr>
		<td>EventEnqueuedUtcTime</td>
		<td>事件中心收到事件的日期和时间。</td>
	</tr>
	<tr>
		<td>PartitionId</td>
		<td>输入适配器的从零开始的分区 ID。</td>
	</tr>
</table>

###输入数据速度很慢甚至没有输入数据的分区
从包含多个分区的输入源读取数据且一个或多个分区在时间上延后或根本没有数据时，流处理作业需要确定如何处理这种情况，以便让事件能够源源不断地流经整个系统。输入设置“允许最长时间的到达延迟”控制着该行为，默认情况下设置为无限期地等待数据，这意味着事件的时间戳不会改变，而且事件的流速取决于最慢的输入分区，在一个或多个输入分区没有数据的情况下事件会停止流动。如果各个输入分区的数据分布很均衡且事件之间的时间一致性很重要，则可以使用这种设置。

你还可以自行决定是否只等待有限的时间：“允许最长时间的到达延迟”会确定一个延迟时间，在该时间之后，作业可以决定是否跳过该事件继续执行相关操作，将延迟的输入分区放在后面，然后根据“晚到事件的操作”设置来处理事件，即如果事件晚到，则可以删除该事件或调整事件的时间戳。在延迟很严重且允许改变时间戳，但输入的分布不均衡的情况下，此设置很有用。

###顺序混乱事件的分区
当流式处理作业查询使用 TIMESTAMP BY 关键字时，将无法保证要输入的事件的到达顺序。同一输入分区中，某些事件可能会延迟，而参数“输入中允许的最大无序程度”会导致流式处理作业根据“晚到事件的操作”设置对超出顺序容许度的事件进行处理，删除这些事件或调整这些事件的时间戳。

### 其他资源
有关创建输入源的详细信息，请参阅 [Azure 事件中心开发人员指南](http://msdn.microsoft.com/zh-cn/library/azure/dn789972.aspx)和[使用 Azure Blob 存储](/documentation/articles/storage-dotnet-how-to-use-blobs)。



## 查询
传入数据的筛选、操作和处理逻辑在流分析作业的查询中定义。查询是使用流分析查询语言编写的，该语言是一种类似 SQL 的语言，大致可以说是标准 Transact-SQL 语法的一部分，针对临时查询进行了一些特定的扩展。

### 开窗
使用开窗扩展可以对特定时间段的部分事件执行聚合和计算操作。开窗函数是通过 **GROUP BY** 语句调用的。例如，以下查询将计算每秒接收的事件的数目：

	SELECT Count(*) 
	FROM Input1 
	GROUP BY TumblingWindow(second, 1) 

### 执行步骤
对于更复杂的查询，可以使用标准的 SQL 子句 **WITH** 来指定临时的命名结果集。例如，以下查询使用 **WITH** 通过两个执行步骤来执行转换操作：
 
	WITH step1 AS ( 
		SELECT Avg(Reading) as avr 
		FROM temperatureInput1 
		GROUP BY Building, TumblingWindow(hour, 1) 
	) 

	SELECT Avg(avr) AS campus_Avg 
	FROM step1 
	GROUP BY TumblingWindow (day, 1) 

若要了解有关查询语言的详细信息，请参阅 [Azure 流分析查询语言参考](http://go.microsoft.com/fwlink/?LinkID=513299)。

## 输出
输出目标是要向其写入流分析作业结果的地方。当作业处理输入事件时，结果将持续写入输出目标。支持以下输出目标：

- Azure 事件中心 - 在需要将多个流式处理管道组合在一起的情况下（例如将命令发回设备），可以选择事件中心作为输出目标。
- Azure Blob 存储 - Blob 存储可用于将输出长期存档，也可用于存储需要以后处理的数据。
- Azure 表存储 - Azure 表存储是一种结构化的数据存储，对架构的约束较少。不同架构和类型的实体可以存储在相同的 Azure 表中。Azure 表存储可用于持久地存储数据，方便进行高效的检索。有关详细信息，请参阅 [Azure 存储空间简介](/documentation/articles/storage-introduction)和[为 Azure 表存储设计可扩展分区策略](https://msdn.microsoft.com/zh-cn/library/azure/hh508997.aspx)。
- Azure SQL 数据库 - 此输出目标适用于本质上为关系型数据的数据，或者适用于所依赖的内容在数据库中托管的应用程序。

## 流式处理单位 ##
Azure 流分析使用流式处理单位 (SU) 来代表执行作业的资源和能力，以便为客户提供可预测性更强的性能体验。在已经对 CPU、内存以及读取和写入速率进行测量的情况下，可以使用 SU 来描述相对的事件处理能力。每个流式处理单位大致相当于 1MB/秒的吞吐量。每个 Azure 流分析作业至少需要一个流式处理单位，这是所有作业的默认设置。若要详细了解如何为作业选择适当数量的 SU，请参阅[缩放 Azure 流分析作业](/documentation/articles/stream-analytics-scale-jobs)

## 缩放作业

下面定义的 SU 利用率百分比度量值是一个指标，表示到底有多需要对 Azure 流分析作业进行缩放。SU 利用率百分比较高可能是因为查询中的窗口较大、输入中的事件较大、超出顺序容许度的窗口较大，或者是因为上述因素的组合。若要防止出现此类情况，可以使用两种策略，一是对查询分区，二是将查询分解成多个步骤，然后从“缩放”选项卡中添加更多的 SU。

即使在没有输入事件的情况下，你可能也会观察到一个基准的资源利用率，因为系统会消耗一定数量的资源。系统消耗的资源量也会随时间而波动。

有关详细信息，请参阅[缩放 Azure 流分析作业](/documentation/articles/stream-analytics-scale-jobs)。


## 作业的监视和故障排除

### 区域监视存储帐户

为了启用作业监视功能，流分析要求你指定一个 Azure 存储帐户，用于监视每个包含流分析作业的区域的数据。这是在创建作业时配置的。

### 度量值
以下度量值可用于监视流分析作业的使用情况和性能：

- SU 利用率百分比 - 一个指标，表示一个或多个查询步骤的相对事件处理能力。如果此指标达到 80% 或以上，则很可能会出现事件处理延迟或停止处理的情况。
- 错误数 - 某项流分析作业引发的错误消息数。
- 输入事件数 - 流分析作业收到的数据量，以事件计数来衡量。
- 输出事件数 - 流分析作业发送到输出目标的数据量，以事件计数来衡量。
- 无序事件数 - 收到的无序事件的数目，系统根据无序策略来删除这些事件，或者为其提供一个经过调整的时间戳。
- 数据转换错误数 - 流分析作业导致的数据转换错误的数目。

### 操作日志
对流分析作业进行调试或故障排除的最佳方式是通过 Azure 操作日志。操作日志可以在门户的**“管理服务”**部分进行访问。若要查看作业的日志，可将**“服务类型”**设置为**“流分析”**，将**“服务名称”**设置为作业的名称。


## 管理作业 

### 启动和停止作业
启动作业时，系统会提示你指定一个**“开始输出”**值，该值决定了此作业何时开始生成相应的输出。如果关联的查询包含一个窗口，则在所需的窗口时段开始时，该作业就会开始从输入源中选取输入，以便在指定的时间生成首个输出事件。有三个选项：**“作业开始时间”**、**“自定义”**和**“上次停止时间”**。默认设置为**“作业开始时间”**。如果临时停止某项作业，则在选择**“开始输出”**值时，最好是选择**“上次停止时间”**，以便恢复上次输出时间的作业，避免丢失数据。对于**“自定义”**选项，则必须指定日期和时间。使用此设置，可以在输入源中指定要使用的历史数据的多少，还可以从特定的时间选取数据引入。

### 配置作业
你可以调整针对流分析作业的以下顶级设置：

- **开始输出** - 使用此设置指定该作业何时开始生成相应的输出。如果关联的查询包含一个窗口，则在所需的窗口时段开始时，该作业就会开始从输入源中选取输入，以便在指定的时间生成首个输出事件。有两个选项：**“作业开始时间”**和**“自定义”**。默认设置为**“作业开始时间”**。对于**“自定义”**选项，则必须指定日期和时间。使用此设置，可以在输入源中指定要使用的历史数据的多少，还可以从特定的时间（例如上次停止作业的时间）选取数据引入。 
- **无序策略** - 一种设置，适用于处理不按顺序到达流分析作业的事件。你可以指定一个容许度窗口，以便确定一个时间阈值来重排事件的顺序；你还可以确定一个操作，以便在事件超出该窗口时对事件执行该操作，该操作就是：**删除**或**调整**。**删除**：将删除所有接收到的无序事件；**调整**：将对系统进行更改。从无序事件的时间戳到最近收到的有序事件的时间戳。 
- **晚到策略** - 从包含多个分区的输入源读取数据且一个或多个分区在时间上延后或根本没有数据时，流处理作业需要确定如何处理这种情况，以便让事件能够源源不断地流经整个系统。输入设置“允许最长时间的到达延迟”控制着该行为，默认情况下设置为无限期地等待数据，这意味着事件的时间戳不会改变，而且事件的流速取决于最慢的输入分区，在一个或多个输入分区没有数据的情况下事件会停止流动。如果各个输入分区的数据分布很均衡且事件之间的时间一致性很重要，则可以使用这种设置。用户还可以自行决定是否只等待有限的时间：“允许最长时间的到达延迟”会确定一个延迟时间，在该时间之后，作业可以决定是否跳过该事件继续执行相关操作，将延迟的输入分区放在后面，然后根据“晚到事件的操作”设置来处理事件，即如果事件晚到，则可以删除该事件或调整事件的时间戳。在延迟很严重且允许改变时间戳，但输入的分布不均衡的情况下，此设置很有用。
- **区域设置** - 使用此设置来指定流分析作业的国际化首选项。虽然数据的时间戳与区域设置无关，但此处的设置会影响作业采用何种方式对数据进行分析、比较和排序。预览版仅支持 **zh-CN** 区域设置。

### 状态

可以在 Azure 门户中检查流分析作业的状态。运行的作业的状态可能为下述两种状态之一：**正在运行**或**已降级**。以下是每一种状态的定义：

- **正在运行** - 作业已分配，正在处理输入，或者正等着处理输入。如果作业显示“正在运行”状态但却没有生成输出，则可能是因为数据处理时间窗口较大，或者查询逻辑较复杂。另一个可能的原因是当前没有任何需要发送给该作业的数据。
- **已降级** - 此状态表示流分析作业遇到下列错误之一：输入/输出通信错误、查询错误或可重试的运行时错误。若要区分作业遇到哪种类型的错误，请查看操作日志。


## 获取支持
如需进一步的帮助，请尝试我们的 [Azure 流分析论坛](https://social.msdn.microsoft.com/Forums/zh-CN/home?forum=AzureStreamAnalytics)。


## 后续步骤

现在，你已经熟悉了流分析的关键概念，你可以尝试阅读以下内容：

- [Azure 流分析简介](/documentation/articles/stream-analytics-introduction)
- [Azure 流分析入门](/documentation/articles/stream-analytics-get-started)
- [缩放 Azure 流分析作业](/documentation/articles/stream-analytics-scale-jobs)
- [Azure 流分析查询语言参考](https://msdn.microsoft.com/zh-cn/library/azure/dn834998.aspx)
- [Azure 流分析管理 REST API 参考](https://msdn.microsoft.com/zh-cn/library/azure/dn835031.aspx)
 

<!---HONumber=69-->